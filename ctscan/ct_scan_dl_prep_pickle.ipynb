{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For traning speed, define DATASET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covid19\n",
      "Normal\n",
      "Pneumonia\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../../dataset/ctscan/3A_images_resized/all\"\n",
    "\n",
    "all_files = []\n",
    "\n",
    "for i in os.listdir(dataset_path):  # Get all the files from the directory in a two element list. First element is list of file location to covid images and second element is list of file location to non-covid images.\n",
    "  print(i)\n",
    "  file1 = glob.glob(os.path.join(dataset_path,i, \"*.png\"))\n",
    "  file2 = glob.glob(os.path.join(dataset_path,i, \"*.jpg\")) # .jpg files are also present.\n",
    "  file1.extend(file2)  # Only extends when there is .jpg file present\n",
    "  all_files.append(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 # Count to record the ids of files. Each file has a unique ID.\n",
    "img_size = 224\n",
    "def get_dataset(files, label, count):\n",
    "  dataset = []  # List to hold all the dataset. Each element is a dictionary\n",
    "\n",
    "  for j in tqdm(files):  # Loop over each file location\n",
    "    data_dict = {}\n",
    "    data_dict[\"id\"] = count\n",
    "    data_dict[\"filepath\"] = j\n",
    "    img = cv2.imread(j)\n",
    "    img = cv2.resize(img,(img_size,img_size))\n",
    "    data_dict[\"image\"] = img\n",
    "    data_dict[\"label\"] = label\n",
    "    count += 1\n",
    "    dataset.append(data_dict)\n",
    "  return dataset, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6334/6334 [00:43<00:00, 144.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6332/6332 [00:25<00:00, 244.92it/s]\n"
     ]
    }
   ],
   "source": [
    "neg_dataset, pos_dataset, t_dataset = [], [], []\n",
    "\n",
    "for i, data in enumerate(all_files[:2]): # 0 - covid, 1 - noncovid, 2 - Phnumonia(exclude)\n",
    "  print(i)\n",
    "  if i == 0:\n",
    "    dataset, count = get_dataset(data, 1, count)\n",
    "    neg_dataset = dataset\n",
    "  else:\n",
    "    dataset, count = get_dataset(data, 0 ,count)\n",
    "    pos_dataset = dataset\n",
    "t_dataset = neg_dataset[:2200] + pos_dataset[:2200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_only, label_only, id_only, img_name = [], [], [], []\n",
    "for data in t_dataset:\n",
    "  image_only.append(data[\"image\"])\n",
    "  label_only.append(data[\"label\"])\n",
    "  id_only.append(data['id'])\n",
    "  img_name.append(data[\"filepath\"].split(\"/\")[-1])\n",
    "image_only = np.array(image_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_datagen = ImageDataGenerator()\n",
    "batch_img= img_datagen.flow(image_only, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_models(img_size, model_sel):\n",
    "  if model_sel == 1:\n",
    "    vgg_pre_t = VGG16(input_shape = (img_size, img_size, 3),include_top = False, weights ='imagenet')\n",
    "    return vgg_pre_t, 25088\n",
    "\n",
    "  elif model_sel==2:\n",
    "    resnet_pre_t= ResNet101(input_shape = (img_size, img_size, 3),include_top=False, weights='imagenet')\n",
    "    return resnet_pre_t, 100352\n",
    "\n",
    "  elif model_sel==3:\n",
    "    densenet169_pre_t = DenseNet169(input_shape = (img_size, img_size, 3),include_top = False, weights ='imagenet' )\n",
    "    return densenet169_pre_t, 81536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_model = 1 # int(input(\"Enter the number for: \\n 1) VGG16 \\n 2) Resnet101  \\n 3) Densenet161 \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████                                                        | 1/3 [00:03<00:07,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:07<00:03,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 31ms/step\n",
      "13/13 [==============================] - 1s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:09<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "all_fea = []\n",
    "model, feature_size = all_models(img_size, select_model)\n",
    "for data in tqdm(range(len(batch_img))):\n",
    "  try:\n",
    "    features = model.predict(batch_img[data]).flatten().reshape(batch_size, feature_size)\n",
    "  except:\n",
    "    img_len = len(batch_img[data])\n",
    "    features = model.predict(batch_img[data]).flatten().reshape(img_len, feature_size)\n",
    "  all_fea.extend(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(t_dataset)):\n",
    "  t_dataset[i]['image']= all_fea[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../pickle_files/al/ct_scan/\"\n",
    "if select_model == 1:\n",
    "  filename = f\"ct_scan_resized_{len(t_dataset)}_vgg16.pickle\"\n",
    "elif select_model == 2:\n",
    "  filename = f\"ct_scan_resized_{len(t_dataset)}_resnet101.pickle\"\n",
    "elif select_model == 3:\n",
    "  filename = f\"ct_scan_resized_{len(t_dataset)}_densenet169.pickle\"\n",
    "\n",
    "file = filepath + filename\n",
    "with open(file, 'wb') as handle:\n",
    "  pickle.dump(t_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset: 4400\n",
      "Sample feature dataset Covid: {'id': 12666, 'filepath': '../../dataset/ctscan/3A_images_resized/all\\\\Covid19\\\\NCP_1013_2577_0000.png', 'image': array([0.      , 0.      , 0.      , ..., 0.      , 9.833735, 0.      ],\n",
      "      dtype=float32), 'label': 1}\n",
      "Sample feature dataset Non-Covid: {'id': 19000, 'filepath': '../../dataset/ctscan/3A_images_resized/all\\\\Normal\\\\Normal_1671_793_0000.png', 'image': array([ 0.     ,  0.     , 22.64142, ...,  0.     ,  0.     ,  0.     ],\n",
      "      dtype=float32), 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Dataset: {}\".format(len(t_dataset)))\n",
    "print(\"Sample feature dataset Covid: {}\".format(t_dataset[0]))\n",
    "print(\"Sample feature dataset Non-Covid: {}\".format(t_dataset[2200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
