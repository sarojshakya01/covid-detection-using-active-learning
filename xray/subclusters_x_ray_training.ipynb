{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required python libraries         \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from statistics import mode\n",
    "\n",
    "\n",
    "# OpenCV and scikit-learn\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances, cosine_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2 \n",
    "\n",
    "# Pandas \n",
    "# import pandas as pd\n",
    "\n",
    "# Tensorflow\n",
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "# from tensorflow.keras.applications.densenet import DenseNet169\n",
    "# from tensorflow.keras.applications.vgg16 import VGG16\n",
    "# from tensorflow.keras.applications.resnet import ResNet101 \n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_model = 2 # int(input(\"Enter the number for: \\n 1) VGG16 \\n 2) Resnet101  \\n 3) Densenet161 \"))\n",
    "\n",
    "select_distance = 3 # int(input(\"Enter the number for: \\n 1) Euclidean  \\n 2) Manhattan \\n 3) Cosine\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../dataset/xray/resized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covid\n",
      "Noncovid\n",
      "Tuberculosis\n"
     ]
    }
   ],
   "source": [
    "labels = [0,1] # 1 = Covid // 0 = Noncovid \n",
    "\n",
    "all_files = []\n",
    "\n",
    "for i in os.listdir(dataset_path):  # Get all the files from the directory in a two element list. First element is list of file location to covid images and second element is list of file location to non-covid images.\n",
    "  print(i)\n",
    "  file1 = glob.glob(os.path.join(dataset_path,i, \"*.png\"))\n",
    "  file2 = glob.glob(os.path.join(dataset_path,i, \"*.jpg\")) # .jpg files are also present.\n",
    "  file1.extend(file2)  # Only extends when there is .jpg file present\n",
    "  all_files.append(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0     # Count to record the ids of files. Each file has a unique ID.\n",
    "img_size = 224\n",
    "def get_dataset(files, label,count):        \n",
    "  dataset=[]  # List to hold all the dataset. Each element is a dictionary\n",
    "  \n",
    "  for j in tqdm(files):  # Loop over each file location\n",
    "    data_dict = {}  \n",
    "    data_dict[\"id\"] = count\n",
    "    data_dict[\"filepath\"] = j\n",
    "    img=cv2.imread(j)\n",
    "    img = cv2.resize(img,(img_size,img_size))\n",
    "    data_dict[\"image\"]= img\n",
    "    data_dict[\"label\"]= label\n",
    "    count +=1\n",
    "    dataset.append(data_dict)\n",
    "  return dataset, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████▍                                       | 1032/2124 [00:07<00:08, 135.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_files[:\u001b[38;5;241m2\u001b[39m]): \u001b[38;5;66;03m# 0 - covid, 1 - noncovid, 2 - tuber(exclude)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m   \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m----> 5\u001b[0m   dataset,count\u001b[38;5;241m=\u001b[39m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      7\u001b[0m     c_dataset \u001b[38;5;241m=\u001b[39m dataset\n",
      "Cell \u001b[1;32mIn[83], line 10\u001b[0m, in \u001b[0;36mget_dataset\u001b[1;34m(files, label, count)\u001b[0m\n\u001b[0;32m      8\u001b[0m data_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m count\n\u001b[0;32m      9\u001b[0m data_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m j\n\u001b[1;32m---> 10\u001b[0m img\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img,(img_size,img_size))\n\u001b[0;32m     12\u001b[0m data_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c_dataset, nc_dataset, t_dataset = [], [], []  \n",
    "\n",
    "for i,data in enumerate(all_files[:2]): # 0 - covid, 1 - noncovid, 2 - tuber(exclude)\n",
    "  print(i)\n",
    "  dataset,count=get_dataset(data,labels[i],count)\n",
    "  if i==0:\n",
    "    c_dataset = dataset\n",
    "  else:\n",
    "    nc_dataset = dataset\n",
    "t_dataset = c_dataset + nc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(t_dataset))\n",
    "batch_size=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_only, label_only, id_only, img_name = [], [], [], []\n",
    "for data in t_dataset:\n",
    "  image_only.append(data[\"image\"])\n",
    "  label_only.append(data[\"label\"]) \n",
    "  id_only.append(data['id'])\n",
    "  img_name.append(data[\"filepath\"].split(\"/\")[-1])\n",
    "image_only=np.array(image_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "\n",
    "img_datagen = ImageDataGenerator()\n",
    "batch_img= img_datagen.flow(image_only, batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_models(img_size, model_sel):\n",
    " \n",
    "  if model_sel == 1:\n",
    "    vgg_pre_t = VGG16(input_shape = (img_size, img_size, 3),include_top = False, weights ='imagenet')\n",
    "    return vgg_pre_t, 25088\n",
    "\n",
    "  elif model_sel==2:\n",
    "    resnet_pre_t= ResNet101(input_shape = (img_size, img_size, 3),include_top=False, weights='imagenet')\n",
    "    return resnet_pre_t, 100352\n",
    "\n",
    "  elif model_sel==3:\n",
    "    densenet169_pre_t = DenseNet169(input_shape = (img_size, img_size, 3),include_top = False, weights ='imagenet' )\n",
    "    return densenet169_pre_t, 81536\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fea = []\n",
    "model,feature_size= all_models(img_size, select_model)\n",
    "for data in tqdm(range(len(batch_img))):\n",
    "  try:\n",
    "    features = model.predict(batch_img[data]).flatten().reshape(batch_size,feature_size)\n",
    "  except:\n",
    "    img_len=len(batch_img[data])\n",
    "    features = model.predict(batch_img[data]).flatten().reshape(img_len,feature_size)\n",
    "  all_fea.extend(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(t_dataset)):\n",
    "  t_dataset[i]['image']= all_fea[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../pickle_files/al/x_ray/x_ray_resnet101.pickle','rb') as handle:\n",
    "   t_dataset  = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4400"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 3094,\n",
       " 'filepath': '../dataset/xrays/Noncovid/normal/NORMAL(48).png',\n",
       " 'image': array([0.       , 0.       , 0.       , ..., 0.       , 7.4171534,\n",
       "        0.       ], dtype=float32),\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(42)\n",
    "shuffle(t_dataset)\n",
    "t_dataset.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_clusters(features):\n",
    "    sum_of_squared_distances = []\n",
    "    no_cluster=[]\n",
    "    K=range(2,21,2)\n",
    "    for num_clusters in K:\n",
    "        kmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init=\"auto\")\n",
    "        kmeans.fit(features)\n",
    "        no_cluster.append(num_clusters)\n",
    "        sum_of_squared_distances.append(kmeans.inertia_)\n",
    "    print(sum_of_squared_distances)\n",
    "    output= kmeans.labels_\n",
    "    clusters = [np.squeeze(np.array(features)[[np.where(output==i)[0]]],axis=0) for i in range(len(np.unique(output)))]\n",
    "    return kmeans.cluster_centers_, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_clusters(features):\n",
    "    kmeans = KMeans(n_clusters=5, random_state=0, n_init=\"auto\").fit(features)\n",
    "    output= kmeans.labels_\n",
    "    clusters = [np.squeeze(np.array(features)[[np.where(output==i)[0]]],axis=0) for i in range(len(np.unique(output)))]\n",
    "    return kmeans.cluster_centers_, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_separation(dataset,label):\n",
    "    add_data= []\n",
    "    i=0\n",
    "    while len(add_data)!=20:\n",
    "        if dataset[i][\"label\"]==label:\n",
    "            add_data.append(dataset[i]['image'])\n",
    "            del dataset[i]\n",
    "        i+=1\n",
    "    return add_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_features(positive, negative):\n",
    "    # print(f\"pure_pf: {positive}\")\n",
    "    # print(f\"p_type: {type(positive)}\")\n",
    "    # print(f\"len_p: {len(positive)}\")\n",
    "    mpos_features=np.array([np.mean(i,axis=0) for i in positive])  # Mean of all positive sub clusters \n",
    "    mneg_features=np.array([np.mean(i,axis=0) for i in negative])  # Mean of all negative sub clusters\n",
    "    # print(mpos_features)\n",
    "    return mpos_features, mneg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[    2],\n",
       "              [    5],\n",
       "              [   22],\n",
       "              [   90],\n",
       "              [71068]]), list([[52], [28], [1]]),\n",
       "       list([[44], [28, 27], [54], [97], [89]]), list([[42], [35], [82]])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[[2],[5],[22],[90]], \n",
    "            [[52],[28],[1]],\n",
    "            [[44],[28,27],[54],[97],[89]],\n",
    "            [[42],[35],[82]]],dtype=object)\n",
    "# np.argmax(np.array(a))\n",
    "# b=np.concatenate((a[-1],np.array([[69]])),axis=0)\n",
    "# b = np.append(a[0],np.array([[99,20,0,9]]),axis=0)\n",
    "# b=np.array([99,20,0,9])\n",
    "# np.insert(a,np.array([[99,20,0,9]]))\n",
    "# c=np.stack((a,b))\n",
    "# z=list(a)\n",
    "# z.append(np.array([[43,67,86]]))\n",
    "a[0]=np.concatenate((a[0],[[71068]]),axis=0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_subclusters(all_dist, query, fea_label, id_pred, label_pred, features, decision, n_neighbours, cluster):\n",
    "    max_ind=np.argmax(all_dist)\n",
    "    features[max_ind]=np.concatenate((features[max_ind],np.expand_dims(query[\"image\"], axis=0)),axis=0)\n",
    "    # fea_label[cluster].append(np.expand_dims(query[\"image\"], axis=0))  # Have doubt here\n",
    "    id_pred[cluster].append(query[\"id\"])\n",
    "    label_pred[cluster].append((query['id'],decision.count(1)/n_neighbours))\n",
    "    return features, fea_label, id_pred, label_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_mispredictions(query, fea_label,train_label, train_id, ind_data, decision,data_frame_1, count, pos_dist, neg_dist, pos_features, neg_features):\n",
    "    if mode(decision) != query[\"label\"]:\n",
    "        # print(\"here\")\n",
    "        count +=1 \n",
    "        data_frame_1[\"Image name\"].append(query[\"filepath\"].split(\"/\")[-1])\n",
    "        data_frame_1[\"Mistake ID\"].append(query['id'])\n",
    "        data_frame_1[\"Original label\"].append(query['label'])\n",
    "        data_frame_1[\"Predicted label\"].append(mode(decision))\n",
    "        data_frame_1[\"Mistake index\"].append(ind_data)\n",
    "        if query[\"label\"]==1:\n",
    "            # pos_features_list= list(pos_features)\n",
    "            pos_features.append(np.expand_dims(query[\"image\"], axis=0))\n",
    "            # pos_features = np.array(pos_features_list)\n",
    "            # pos_features= np.concatenate((pos_features,np.expand_dims(query[\"image\"], axis=0)),axis=0)\n",
    "        else:\n",
    "            # neg_features_list= list(neg_features)\n",
    "            neg_features.append(np.expand_dims(query[\"image\"], axis=0))\n",
    "            # neg_features = np.array(neg_features_list)\n",
    "            # neg_features = np.concatenate((neg_features,np.expand_dims(query[\"image\"], axis=0)),axis=0)\n",
    "        train_label[query['label']].append(query[\"label\"])\n",
    "        train_id[query['label']].append(query['id'])\n",
    "\n",
    "    else:\n",
    "        if query['label'] == 0:\n",
    "            max_ind = np.argmin(neg_dist)\n",
    "            neg_features[max_ind] = np.concatenate((neg_features[max_ind],np.expand_dims(query[\"image\"], axis=0)),axis=0)\n",
    "            # fea_label[query['label']].append(np.concatenate((fea_label[query['label']],np.expand_dims(query[\"image\"], axis=0)),axis=0))\n",
    "        else:\n",
    "            max_ind = np.argmin(pos_dist)\n",
    "\n",
    "            pos_features[max_ind] = np.concatenate((pos_features[max_ind],np.expand_dims(query[\"image\"], axis=0)),axis=0)\n",
    "            # fea_label[query['label']].append(np.concatenate((mpos_features,np.expand_dims(query[\"image\"], axis=0)),axis=0))\n",
    "        train_label[query['label']].append(query[\"label\"])\n",
    "        train_id[query['label']].append(query['id'])\n",
    "    return count,data_frame_1,fea_label,train_label,train_id,pos_features,neg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance2(query, fea_label, select_distance, id_pred, label_pred, n_neighbours, count, train_label, train_id, ind_data, data_frame_1, pos_features, neg_features, supervised_data): # Query is the raw dictionary (from pickle file) // fea_label is dictionary of {0: [], 1:[]} (distance) // select distance is int\n",
    "  exp_query = np.expand_dims(query['image'], axis=0)\n",
    "  pos_tup, neg_tup = [], []\n",
    "\n",
    "  if select_distance==1: # Euclidean distance\n",
    "    # print(f\"Type: {type(fea_label[0])}\")\n",
    "    # print(f\"Shape: {fea_label[0].shape}\")\n",
    "    neg_dist = np.linalg.norm(query['image']- fea_label[0], axis=1)  # Calculating the Euclidean distance using numpy (axis=1) to calculate all at ones   \n",
    "    pos_dist = np.linalg.norm(query['image']- fea_label[1], axis=1)\n",
    "\n",
    "  elif select_distance==2: # Manhattan distance\n",
    "    neg_dist = np.squeeze(manhattan_distances(fea_label[0],exp_query))  # convert (1,n) to (,n)\n",
    "    pos_dist=np.squeeze(manhattan_distances(fea_label[1],exp_query))\n",
    "\n",
    "  elif select_distance==3: # Cosine distance\n",
    "    neg_dist = np.squeeze(cosine_distances(exp_query,fea_label[0]))  # convert (1,n) to (,n)\n",
    "    pos_dist=np.squeeze(cosine_distances(exp_query,fea_label[1]))\n",
    "  \n",
    "  for dist_single in pos_dist:\n",
    "    # print(dist_single)\n",
    "    pos_tup.append((dist_single,1))\n",
    "\n",
    "  for dist_single in neg_dist:\n",
    "    neg_tup.append((dist_single,0))\n",
    "\n",
    "  pos_tup.extend(neg_tup)\n",
    "  tup_dist = sorted(pos_tup)[:n_neighbours]\n",
    "  \n",
    "  decision = [y for (x,y) in tup_dist]\n",
    "\n",
    "  if supervised_data:\n",
    "    count,data_frame_1,fea_label,train_label,train_id, pos_features,neg_features=correct_mispredictions(query, fea_label,train_label,train_id, ind_data, decision,data_frame_1, count, pos_dist, neg_dist, pos_features, neg_features)\n",
    "    \n",
    "  else:\n",
    "    if decision.count(0) > decision.count(1):\n",
    "      neg_features, fea_label, id_pred, label_pred = update_subclusters(neg_dist,query,fea_label,id_pred,label_pred,neg_features, decision, n_neighbours, cluster=0)\n",
    "      \n",
    "    else:\n",
    "      pos_features, fea_label, id_pred, label_pred = update_subclusters(pos_dist,query,fea_label,id_pred,label_pred,pos_features, decision,n_neighbours, cluster=1)\n",
    "  \n",
    "  return id_pred, label_pred, data_frame_1, count, train_label, train_id, pos_features, neg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(label_gt,id_pred):\n",
    "  TP,FP,FN,TN = 0,0,0,0\n",
    "\n",
    "  for tp in id_pred[1]:   # TP --> When correctly classified covid\n",
    "    if tp in label_gt[1]:\n",
    "      TP +=1\n",
    "\n",
    "  for tn in id_pred[0]:  # TN --> When correctly classified healthy (non-covid)\n",
    "    if tn in label_gt[0]:\n",
    "      TN +=1\n",
    "\n",
    "  for fp in id_pred[1]: # FP --> When incorrectly classified healthy (Classified healthy as covid)\n",
    "    if fp in label_gt[0]:\n",
    "      FP +=1\n",
    "\n",
    "  for fn in id_pred[0]: # FN --> When missed covid classification (Covid cases missed)\n",
    "    if fn in label_gt[1]:\n",
    "      FN +=1\n",
    "\n",
    "  accuracy= (TP+TN)/(TP+TN+FP+FN)\n",
    "  specificity = TN/(TN+FP)\n",
    "  sensitivity = (TP)/(TP+FN)\n",
    "  # f1_score = (2*precision*recall)/(precision + recall)\n",
    "  \n",
    "  print(\"TP: \", TP)\n",
    "  print(\"FP: \", FP)\n",
    "  print(\"FN: \", FN)\n",
    "  print(\"TN: \", TN)\n",
    "\n",
    "  return accuracy, specificity, sensitivity,TP,TN,FP,FN\n",
    "\n",
    "def roc_auc_curve(label_gt,label_pred):\n",
    "  gt_labels= sorted(label_gt[0]+ label_gt[1])  # Contains (id,labels) tuple of binary class \n",
    "  pred_labels = sorted(label_pred[0]+label_pred[1]) # Contains (id,labels) tuple of binary class --> sorted to match each element in gt_labels and pred_labels\n",
    "  y_test = [y for (x,y) in gt_labels]   # Get only the labels\n",
    "  y_scores = [y for (x,y) in pred_labels]\n",
    "  fpr, tpr, threshold = roc_curve(y_test, y_scores)\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "  return roc_auc\n",
    "\n",
    "def cluster_metrics(pos_features, neg_features, train_label,id_pred):\n",
    "  print(\"Calculating Dunn's index...\")\n",
    "  intra_dist1 = euclidean_distances(neg_features).max()\n",
    "  intra_dist2 = euclidean_distances(pos_features).max()\n",
    "  inter_dist = euclidean_distances(neg_features,pos_features).min()\n",
    "\n",
    "  if intra_dist1>intra_dist2:\n",
    "    max_intra_dist= intra_dist1  \n",
    "  else:\n",
    "    max_intra_dist = intra_dist2 \n",
    "\n",
    "  Dunn_index = inter_dist/max_intra_dist\n",
    "\n",
    "  print(\"Calculating Davies Bouldin index...\")\n",
    "\n",
    "  # Davies Bouldin and Silhouette score from sklearn library.\n",
    "  class_0 =np.concatenate((np.zeros(shape=(len(train_label[0])),dtype=int),np.zeros(shape=(len(id_pred[0])),dtype=int),np.zeros(shape=(20),dtype=int)))\n",
    "  class_1 = np.concatenate((np.ones(shape=(len(train_label[1])),dtype=int),np.ones(shape=(len(id_pred[1])),dtype=int),np.zeros(shape=(20),dtype=int)))\n",
    "  class_all = np.concatenate((class_0,class_1))\n",
    "  feature_all = np.concatenate((neg_features,pos_features))\n",
    "\n",
    "  davies_bouldin_index = davies_bouldin_score(feature_all,class_all)\n",
    "  silhouette_index = silhouette_score(feature_all,class_all)\n",
    "\n",
    "  print(\"davies: \", davies_bouldin_index)\n",
    "  print(\"silhouette_sklearn: \", silhouette_index)\n",
    "  \n",
    "  return Dunn_index,davies_bouldin_index, silhouette_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled_size = [200,400,800,1100,1300,1550]\n",
    "labeled_size = [200,400,800,1550]\n",
    "# labeled_size = [1550]\n",
    "def data_loader(dataset,n): # Method to return three sets of labeled dataset for experiment\n",
    "  labeled_data, unlabeled_data = [], [] \n",
    "\n",
    "  l_data = dataset[:n]    # First dataset // labeled\n",
    "  ul_data = dataset[n:]   # First dataset // unlabeled\n",
    "  labeled_data.append(l_data)\n",
    "  unlabeled_data.append(ul_data)\n",
    "\n",
    "  l_data = dataset[1500:1500+n]    # second dataset // labeled\n",
    "  ul_data = dataset[:1500]+dataset[1500+n:]\n",
    "  labeled_data.append(l_data)\n",
    "  unlabeled_data.append(ul_data)\n",
    "\n",
    "  l_data = dataset[3000:3000+n]     # Third dataset // labeled\n",
    "  ul_data = dataset[:3000]+dataset[3000+n:]\n",
    "  labeled_data.append(l_data)\n",
    "  unlabeled_data.append(ul_data)\n",
    "  return labeled_data, unlabeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_features(features):\n",
    "    all_features = []\n",
    "    for i in features:\n",
    "        for j in i:\n",
    "            all_features.append(j)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4199/4199 [08:24<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  2029\n",
      "FP:  2170\n",
      "FN:  0\n",
      "TN:  0\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  7.814506818241465\n",
      "silhouette_sklearn:  -0.01526129\n",
      "Labeled image: 200 \t Dataset: d_0 \t Accuracy: 0.48321028816384853 \t Specificity: 0.0 \t Sensitivity: 1.0 \t Dunn index: 7.287181347237492e-08  \t Davies Bouldin: 7.814506818241465 \t Silhouette index: -0.015261289663612843 \t AUC: 0.5 \t Corrected count: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4199/4199 [08:27<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  1995\n",
      "FP:  37\n",
      "FN:  30\n",
      "TN:  2137\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  3.0803932581999303\n",
      "silhouette_sklearn:  0.09162295\n",
      "Labeled image: 200 \t Dataset: d_1 \t Accuracy: 0.9840438199571326 \t Specificity: 0.9829806807727691 \t Sensitivity: 0.9851851851851852 \t Dunn index: 0.19569629430770874  \t Davies Bouldin: 3.0803932581999303 \t Silhouette index: 0.09162294864654541 \t AUC: 0.9851653094370053 \t Corrected count: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4199/4199 [10:06<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  2026\n",
      "FP:  2173\n",
      "FN:  0\n",
      "TN:  0\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  7.08479814809851\n",
      "silhouette_sklearn:  -0.0066608135\n",
      "Labeled image: 200 \t Dataset: d_2 \t Accuracy: 0.4824958323410336 \t Specificity: 0.0 \t Sensitivity: 1.0 \t Dunn index: 0.3736218214035034  \t Davies Bouldin: 7.08479814809851 \t Silhouette index: -0.006660813465714455 \t AUC: 0.5 \t Corrected count: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3999/3999 [08:37<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  1899\n",
      "FP:  29\n",
      "FN:  38\n",
      "TN:  2033\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  3.0837354939367496\n",
      "silhouette_sklearn:  0.0915681\n",
      "Labeled image: 400 \t Dataset: d_0 \t Accuracy: 0.9832458114528632 \t Specificity: 0.9859359844810863 \t Sensitivity: 0.9803820340733093 \t Dunn index: 0.09121125936508179  \t Davies Bouldin: 3.0837354939367496 \t Silhouette index: 0.09156809747219086 \t AUC: 0.9878858634774244 \t Corrected count: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3999/3999 [08:25<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  1886\n",
      "FP:  28\n",
      "FN:  41\n",
      "TN:  2044\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  3.0935950962525305\n",
      "silhouette_sklearn:  0.0910636\n",
      "Labeled image: 400 \t Dataset: d_1 \t Accuracy: 0.9827456864216054 \t Specificity: 0.9864864864864865 \t Sensitivity: 0.9787234042553191 \t Dunn index: 0.09275288134813309  \t Davies Bouldin: 3.0935950962525305 \t Silhouette index: 0.09106359630823135 \t AUC: 0.9878225350786327 \t Corrected count: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3999/3999 [09:28<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  0\n",
      "FP:  0\n",
      "FN:  1929\n",
      "TN:  2070\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  5.5962949946782174\n",
      "silhouette_sklearn:  0.014301361\n",
      "Labeled image: 400 \t Dataset: d_2 \t Accuracy: 0.5176294073518379 \t Specificity: 1.0 \t Sensitivity: 0.0 \t Dunn index: 8.664189010687551e-08  \t Davies Bouldin: 5.5962949946782174 \t Silhouette index: 0.014301360584795475 \t AUC: 0.5007776049766719 \t Corrected count: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3599/3599 [08:55<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  1698\n",
      "FP:  25\n",
      "FN:  45\n",
      "TN:  1831\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  3.093040084567359\n",
      "silhouette_sklearn:  0.09114148\n",
      "Labeled image: 800 \t Dataset: d_0 \t Accuracy: 0.9805501528202278 \t Specificity: 0.9865301724137931 \t Sensitivity: 0.9741824440619621 \t Dunn index: 0.08578385412693024  \t Davies Bouldin: 3.093040084567359 \t Silhouette index: 0.091141477227211 \t AUC: 0.9893448486062477 \t Corrected count: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3599/3599 [08:49<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  1699\n",
      "FP:  25\n",
      "FN:  42\n",
      "TN:  1833\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  3.0972005973115952\n",
      "silhouette_sklearn:  0.09090896\n",
      "Labeled image: 800 \t Dataset: d_1 \t Accuracy: 0.981383717699361 \t Specificity: 0.9865446716899893 \t Sensitivity: 0.9758759333716255 \t Dunn index: 0.10885119438171387  \t Davies Bouldin: 3.0972005973115952 \t Silhouette index: 0.0909089595079422 \t AUC: 0.9907378497071515 \t Corrected count: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3599/3599 [09:01<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  1659\n",
      "FP:  19\n",
      "FN:  74\n",
      "TN:  1847\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  3.112324922810108\n",
      "silhouette_sklearn:  0.090303436\n",
      "Labeled image: 800 \t Dataset: d_2 \t Accuracy: 0.9741594887468741 \t Specificity: 0.9898177920685959 \t Sensitivity: 0.9572994806693594 \t Dunn index: 0.09275288134813309  \t Davies Bouldin: 3.112324922810108 \t Silhouette index: 0.090303435921669 \t AUC: 0.985866685962982 \t Corrected count: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2849/2849 [08:48<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  1328\n",
      "FP:  15\n",
      "FN:  51\n",
      "TN:  1455\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  3.093752091086293\n",
      "silhouette_sklearn:  0.091192625\n",
      "Labeled image: 1550 \t Dataset: d_0 \t Accuracy: 0.9768339768339769 \t Specificity: 0.9897959183673469 \t Sensitivity: 0.9630166787527193 \t Dunn index: 0.06887488067150116  \t Davies Bouldin: 3.093752091086293 \t Silhouette index: 0.09119262546300888 \t AUC: 0.992582863457203 \t Corrected count: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2849/2849 [08:26<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  1355\n",
      "FP:  19\n",
      "FN:  34\n",
      "TN:  1441\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  3.100254546011471\n",
      "silhouette_sklearn:  0.090782665\n",
      "Labeled image: 1550 \t Dataset: d_1 \t Accuracy: 0.9813969813969814 \t Specificity: 0.986986301369863 \t Sensitivity: 0.9755219582433405 \t Dunn index: 0.10885119438171387  \t Davies Bouldin: 3.100254546011471 \t Silhouette index: 0.09078266471624374 \t AUC: 0.9952279160132943 \t Corrected count: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [08:50<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  1375\n",
      "FP:  11\n",
      "FN:  61\n",
      "TN:  1553\n",
      "Calculating Dunn's index...\n",
      "Calculating Davies Bouldin index...\n",
      "davies:  3.104741439928818\n",
      "silhouette_sklearn:  0.09068247\n",
      "Labeled image: 1550 \t Dataset: d_2 \t Accuracy: 0.976 \t Specificity: 0.9929667519181585 \t Sensitivity: 0.9575208913649025 \t Dunn index: 0.19569629430770874  \t Davies Bouldin: 3.104741439928818 \t Silhouette index: 0.09068246930837631 \t AUC: 0.9909150168484495 \t Corrected count: 63\n"
     ]
    }
   ],
   "source": [
    "n_neighbours=15\n",
    "\n",
    "data_frame = {\"Labeled data\": [],\n",
    "              \"Dataset\": [],\n",
    "              \"Accuracy\": [],\n",
    "              \"Specificity\": [],\n",
    "              \"Sensitivity\": [],\n",
    "              \"AUC\":[],\n",
    "              \"Dunn index\": [],\n",
    "              \"Davies Bouldin\": [],\n",
    "              \"Silhouette index\":[],\n",
    "              \"TP\":[],\n",
    "              \"TN\":[],\n",
    "              \"FP\":[],\n",
    "              \"FN\":[],\n",
    "              \"pos_labeled_img\":[],\n",
    "              \"neg_labeled_img\":[],\n",
    "              \"corrected_count\":[]\n",
    "    \n",
    "}\n",
    "# fea_label1={0: [],\n",
    "#             1:[]}\n",
    "\n",
    "\n",
    "for size in labeled_size:\n",
    "  labeled_data, unlabeled_data = data_loader(t_dataset, size)\n",
    "#   print(f\"labeled data length {len(labeled_data)}\")\n",
    "#   print(f\"Unlabeled data length {len(unlabeled_data)}\")\n",
    "  select=0         # To select the dataset out of three sets ==> three sets: [d11, d12, d13] ==> eg: [200,200,200]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  while(select < 3):\n",
    "    data_frame_1 = {  \"Image name\": [],\n",
    "                  \"Mistake index\": [],\n",
    "                  \"Mistake ID\": [],\n",
    "                  \"Original label\": [],\n",
    "                  \"Predicted label\": []\n",
    "                  \n",
    "    }\n",
    "    pos_img, neg_img=0, 0\n",
    "\n",
    "    fpos, fneg= [], []\n",
    "\n",
    "    label_gt = {0: [],    \n",
    "        1 :[]}    \n",
    "                            # Collect the ground truth (label) of all the predicting images\n",
    "    train_label = {0: [],    \n",
    "        1 :[]}    \n",
    "\n",
    "    label_pred = {0: [],\n",
    "        1 :[]}               # Collect the predicted label for all the images\n",
    "\n",
    "    id_gt = {0: [], \n",
    "            1: [] }         # Collect the ground truth (id) of all the predicting images\n",
    "\n",
    "    id_pred = {0: [],\n",
    "            1: []}        # Collect the predicted id for all the images \n",
    "\n",
    "    fea_label = {0: [],\n",
    "            1: []}\n",
    "\n",
    "    train_id ={0: [],\n",
    "            1:[]}\n",
    "        \n",
    "    # print(type(labeled_data[0][0]))\n",
    "    # for data in labeled_data[select]:\n",
    "    #     if data[\"label\"] == 1:\n",
    "    #         fpos.append(data['image'])\n",
    "    #         train_id[1].append(data['id'])\n",
    "    #         train_label[1].append((data['id'],data['label']))\n",
    "    #         pos_img +=1\n",
    "\n",
    "    #     else:\n",
    "    #         fneg.append(data['image'])\n",
    "    #         train_id[0].append(data['id'])\n",
    "    #         train_label[0].append((data['id'],data['label']))\n",
    "    #         neg_img +=1\n",
    "\n",
    "    # print(f\"Blen: {len(labeled_data[select])}\")\n",
    "    fpositive = data_separation(labeled_data[select],1)    # Get 20 features of each class\n",
    "\n",
    "    \n",
    "    fnegative = data_separation(labeled_data[select],0)\n",
    "\n",
    "\n",
    "    mneg_features,neg_features= sub_clusters(fnegative)  # Get the subclusters (Using K-means algorithm)\n",
    "    mpos_features,pos_features= sub_clusters(fpositive)    \n",
    "\n",
    "        \n",
    "\n",
    "    count, ind_data=0, 40\n",
    "    for data in labeled_data[select]:\n",
    "        fea_label={0: mneg_features,\n",
    "            1: mpos_features}\n",
    "        id_pred, label_pred, data_frame_1, count, train_label, train_id, pos_features, neg_features= distance2(data,fea_label,3,id_pred,label_pred,n_neighbours, count, train_label, train_id, ind_data, data_frame_1, pos_features, neg_features, supervised_data=True)\n",
    "        mpos_features, mneg_features = mean_features(pos_features, neg_features)    # Get the mean of the features\n",
    "        ind_data +=1\n",
    "\n",
    "    data_f_1 = pd.DataFrame.from_dict(data_frame_1)\n",
    "    data_f_1.to_csv(f\"./subclusters_csv/mistake/desnenet169_cosine_mistake_{size}_{select}.csv\",index=False) # Chest X-rays\n",
    "\n",
    "    for data in tqdm(unlabeled_data[select]):\n",
    "      if data[\"label\"]==1:\n",
    "        id_gt[1].append(data['id'])\n",
    "        label_gt[1].append((data['id'],data['label']))\n",
    "      \n",
    "      else:\n",
    "        id_gt[0].append(data['id'])\n",
    "        label_gt[0].append((data['id'],data['label']))\n",
    "      \n",
    "      fea_label={0: mneg_features,\n",
    "            1: mpos_features}\n",
    "\n",
    "      id_pred, label_pred, _, _, _, _, pos_features, neg_features = distance2(data,fea_label,3,id_pred,label_pred,n_neighbours, count, train_label, train_id, ind_data, data_frame_1, pos_features, neg_features,supervised_data=False) # ind_data is the index of misclassification\n",
    "      mpos_features, mneg_features = mean_features(pos_features, neg_features)    # Get the mean of the features\n",
    "\n",
    "    accuracy, specificity, sensitivity,TP,TN,FP,FN= classification_metrics(id_gt,id_pred)\n",
    "    flattened_pos_features = flatten_features(pos_features) \n",
    "    flattened_neg_features = flatten_features(neg_features)\n",
    "    dunn_index, davies_bouldin_index, silhouette_index = cluster_metrics(flattened_pos_features, flattened_neg_features, train_label,id_pred)\n",
    "    cl_auc = roc_auc_curve(label_gt,label_pred)\n",
    "    data_frame[\"Labeled data\"].append(size)\n",
    "    data_frame[\"Dataset\"].append(f\"d_{select}\")\n",
    "    data_frame[\"Accuracy\"].append(accuracy)\n",
    "    data_frame[\"Specificity\"].append(specificity)\n",
    "    data_frame[\"Sensitivity\"].append(sensitivity)\n",
    "    data_frame[\"AUC\"].append(cl_auc)\n",
    "    data_frame[\"Dunn index\"].append(dunn_index)\n",
    "    data_frame[\"Davies Bouldin\"].append(davies_bouldin_index)\n",
    "    data_frame[\"Silhouette index\"].append(silhouette_index)\n",
    "    data_frame[\"TP\"].append(TP)\n",
    "    data_frame[\"TN\"].append(TN)\n",
    "    data_frame[\"FP\"].append(FP)\n",
    "    data_frame[\"FN\"].append(FN)\n",
    "    data_frame[\"pos_labeled_img\"].append(pos_img)\n",
    "    data_frame[\"neg_labeled_img\"].append(neg_img)\n",
    "    data_frame[\"corrected_count\"].append(count)\n",
    "\n",
    "    print(f\"Labeled image: {size} \\t Dataset: d_{select} \\t Accuracy: {accuracy} \\t Specificity: {specificity} \\t Sensitivity: {sensitivity} \\t Dunn index: {dunn_index}  \\t Davies Bouldin: {davies_bouldin_index} \\t Silhouette index: {silhouette_index} \\t AUC: {cl_auc} \\t Corrected count: {count}\")\n",
    "    select +=1 \n",
    "\n",
    "    data_f=pd.DataFrame.from_dict(data_frame)\n",
    "    data_f.to_csv(f\"./subclusters_csv/densenet169_cosine_dist.csv\",index=False)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
