{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras.applications.densenet import DenseNet169\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read image file paths and store to a list both for covid and non-covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Files Count\n",
      "Covid: 2124\n",
      "Non-Covid: 2358\n",
      "Total: 4482\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../../dataset/xray/resized\"\n",
    "\n",
    "all_files = []\n",
    "\n",
    "covid_files = glob.glob(os.path.join(dataset_path, \"Covid\", \"*.png\"))\n",
    "covid_files.extend(glob.glob(os.path.join(dataset_path, \"Covid\", \"*.jpg\")))\n",
    "\n",
    "non_covid_files = glob.glob(os.path.join(dataset_path, \"Noncovid\", \"*.png\"))\n",
    "non_covid_files.extend(glob.glob(os.path.join(dataset_path, \"Noncovid\", \"*.jpg\")))\n",
    "\n",
    "# Get all the files from the directory in a two element list. First element is list of file location to covid images and second element is list of file location to non-covid images.\n",
    "all_files = [covid_files, non_covid_files]\n",
    "print(\"Image Files Count\\nCovid: {}\\nNon-Covid: {}\\nTotal: {}\".format(len(covid_files), len(non_covid_files), len(all_files[0] + all_files[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read image from file list and store the corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(files, label, count, img_size):\n",
    "  dataset = []  # List to hold all the dataset. Each element is a dictionary\n",
    "\n",
    "  for j in tqdm(files):  # Loop over each file location\n",
    "    data_dict = {}\n",
    "    data_dict[\"id\"] = count\n",
    "    data_dict[\"filepath\"] = j\n",
    "    try:\n",
    "      img = cv2.imread(j)\n",
    "      img = cv2.resize(img, (img_size, img_size))\n",
    "      data_dict[\"image\"] = img\n",
    "      data_dict[\"label\"] = label\n",
    "      count += 1\n",
    "      dataset.append(data_dict)\n",
    "    except Exception as e:\n",
    "      print(\"faulty image: {} {}\".format(j, e))\n",
    "  return dataset, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read image from the file and store the corresponding label in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2124/2124 [00:06<00:00, 308.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2358/2358 [00:39<00:00, 59.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Count\n",
      "Covid: 2124\n",
      "Non-Covid: 2358\n",
      "Total: 4482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c_dataset, nc_dataset, t_dataset = [], [], []\n",
    "labels = [1, 0] # 1 = Covid, 0 = Noncovid\n",
    "count = 0       # Count to record the ids of files. Each file has a unique ID.\n",
    "img_size = 224\n",
    "# all_files => [NC, C]\n",
    "for i, data in enumerate(all_files): # only two loops for Covid and Non-Covid\n",
    "  dataset, count = get_dataset(data, labels[i], count, img_size)\n",
    "  if labels[i] == 1:\n",
    "    c_dataset = dataset\n",
    "  else:\n",
    "    nc_dataset = dataset\n",
    "tot_dataset = c_dataset + nc_dataset\n",
    "print(\"Dataset Count\\nCovid: {}\\nNon-Covid: {}\\nTotal: {}\".format(len(c_dataset), len(nc_dataset), len(tot_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract image only from the dataset to send to DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_only = []\n",
    "for data in tot_dataset:\n",
    "  image_only.append(data[\"image\"])\n",
    "image_only = np.array(image_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4482\n"
     ]
    }
   ],
   "source": [
    "batch_size = image_only.shape[0]\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate batches of images to feed into DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_datagen = ImageDataGenerator()\n",
    "batch_img = img_datagen.flow(image_only, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to select a model from three (VGG16, ResNet101 and DenseNet169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_models(img_size, model_sel):\n",
    "  if model_sel == 1:\n",
    "    vgg_pre_t = VGG16(input_shape=(img_size, img_size, 3), include_top=False, weights ='imagenet')\n",
    "    return vgg_pre_t, 25088\n",
    "\n",
    "  elif model_sel == 2:\n",
    "    resnet_pre_t= ResNet101(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')\n",
    "    return resnet_pre_t, 100352\n",
    "\n",
    "  elif model_sel == 3:\n",
    "    densenet169_pre_t = DenseNet169(input_shape=(img_size, img_size, 3), include_top=False, weights ='imagenet' )\n",
    "    return densenet169_pre_t, 81536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select model among 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_model = 1 # int(input(\"Enter the number for: \\n 1) VGGNET16 \\n 2) Resnet101  \\n 3) Densenet169 \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract image feature from the selected DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 4s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:22<00:00, 82.25s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "all_features, reduced_features = [], []\n",
    "pca = PCA(n_components=batch_size)\n",
    "\n",
    "all_feat = []\n",
    "model, feature_size = all_models(img_size, select_model)\n",
    "for data in tqdm(range(len(batch_img))):\n",
    "  try:\n",
    "    features = model.predict(batch_img[data]).flatten().reshape(batch_size, feature_size)\n",
    "    feature_matrix = features.reshape(features.shape[0], -1)\n",
    "    reduced_features = pca.fit_transform(feature_matrix)\n",
    "  except:\n",
    "    img_len = len(batch_img[data])\n",
    "    features = model.predict(batch_img[data]).flatten().reshape(img_len, feature_size)\n",
    "    feature_matrix = features.reshape(features.shape[0], -1)\n",
    "    reduced_features = pca.fit_transform(feature_matrix)\n",
    "  all_feat.extend(reduced_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace image value by image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2124, 'filepath': '../../dataset/xray/resized\\\\Noncovid\\\\NORMAL(0).png', 'image': array([-3.5238689e+01,  2.8131027e+02, -9.3958908e+01, ...,\n",
      "        7.2593986e-11,  1.7949255e-10,  7.5264801e-11], dtype=float32), 'label': 0}\n",
      "{'id': 4249, 'filepath': '../../dataset/xray/resized\\\\Noncovid\\\\PNEUMONIA(587).jpg', 'image': array([ 1.6487152e+02, -2.3274074e+02, -3.2769183e+02, ...,\n",
      "        7.2500873e-11,  1.7953106e-10,  7.4546008e-11], dtype=float32), 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tot_dataset)):\n",
    "  tot_dataset[i]['image'] = all_feat[i]\n",
    "\n",
    "# print sample dataset covid and non-covid\n",
    "print(dataset[0])\n",
    "print(dataset[2125])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save extracted feature in pickle file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../pickle_files/al/x_ray/\"\n",
    "if select_model == 1:\n",
    "  filename = \"x_ray_pca_vgg16.pickle\"\n",
    "elif select_model == 2:\n",
    "  filename = \"x_ray_resnet101.pickle\"\n",
    "elif select_model == 3:\n",
    "  filename = \"x_ray_densenet169.pickle\"\n",
    "\n",
    "file = filepath + filename\n",
    "with open(file, 'wb') as handle:\n",
    "  pickle.dump(tot_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
